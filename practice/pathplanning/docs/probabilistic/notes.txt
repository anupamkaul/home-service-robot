Discrete path planning was quite simple and applicable for 2D spaces (like the case of a simple vaccuum cleaner in a room).
However as problems get more complicated and we need to compute across 3D spaces, discrete path planning approaches fall short.

(Applying graph search algorithms to this large space may be too costly)

To tackle path planning problems of larger size and for greater dimensions, a sub category of algorithms falls under "Sample Based Path Planning" category. In this approach, instead of discretizing the entire configuration space, these algos randomly sample the space, hoping that the collection of samples will adequately represent the configuration space.

Two approaches:

1. Sample based path planning
2. Probabilistic path planning     (helps consider uncertainty of robot motion when planning paths)

----

1. Sample based path planning - Random samples are chosen instead of discrete cells

A) PRM - Probabilistic Road Map - In this sample based path planning, random config spaces are chosen (a new random node is chosen) and connection are made to a developing graph (either radius of circle or nearest neighbours on the graph). Any and all edges between the new node and graph (i.e. lateral connections) is only submitted into the graph if it is collision free. Todetect collision, the line can be divided into equally spaced points that are checked for whether they are in a free zone or obstacle. The attached paper shows that binary search for collision on these points of a potential edge is better than linear search. Once a set of nodes has been created and some criteria passed (number of nodes or a time deadline for search etc) then a local planner (like A*) could be applied to find a feasable path that joins the start and end nodes. PRM is a probabilistic-complete algo, i.e. given enough space and time a complete and optimal solution may be found, but as it is probabilistic, it meets its purpose for strict time deadlines and focusses on finding a feasable path. Once a PRM is formed, multiple queries for new paths may be made to the same graph.

B) RRT - Unlike PRM, RRT (Rapidly Exploring Random Tree) is single query. RRT disregards building somewhat of a 'global' graph that PRM does and builds one anew everytime a new query is needed. Thus the graph is smaller but more directed graph with a faster computation time. PRM is great for static envs, but certain envs change very quickly, so RRT may be a better choice there. So: for the first learning part, while PRM built up a graph, RRT will build up a .. tree.  (i.e. a graph where each node has only 1 parent.) The lack of connection between neighboring nodes (in the tree) will be less of a concern for these envs. Algo: Randomly generate a node, find its closest neighbour. If the nearest neigh is less than a certain distance, then add it (local planner will use it so chk it is collision free). However if the nearest node is greater than this certain distance, then it is unlikely that that edge is collision free. In this case, instead of connecting, RRT will create a new node in the Same direction but a distance (delta) away. Now add if collision free. Nodes can be generated by uniformly sampling the search space. Greediness can be introduced by more probability sampling near the goal to bias new samples in the direction of the goal. (Bias is good for single query planners). An alternate version of RRT grows 2 trees, one from start and one from goal. Nodes are inserted alternatively in the 2 trees and at every step, RRT tries to find an edge between the 2 trees. Eventually it succeeds and when it does, RRT knows that a path has been found ! 

While these were simple reps, both PRM and RRT do excellently in path planning for multi dimensional robots with multiple DOFs. They have solved problems that traditional path planning algorithms are unable to solve.

Path Smoothing : The paths created by PRM or RRT may induce "jerky" movements in the robot or car, so a "path smoothing" algo comes in. It just tries to find alternate nearest neighbors to this "path containing" graph (thereby changing a few inner directions) which results in 'smoother' although less-optimal paths. 

While not complete, sampe based path planning algos are said to be probablistic complete, as completeness / optimality grows exponentially as samples are added. Both PRM and RRT are used today in real world path planning for robots ! 

----

2. Probabilistic path planning (ppp)

Both discrete (classical) and sample planning methods have a drawback - they do not take uncertainty of a robot's motion into account. Even on an optimal path, we may actually want to consider this. Yes, one can increase the size of the rover (c space) but then the algo will no longer be complete. Another idea is to give negative values to riskier areas, so that the rover can avoid those, and reconstruct 'safer' paths. This is similar to an RL concept. This may cause the rover to avoid dangerous areas, but it will still not consider the uncertainty of motion.

We wud like to model the uncertainty by considering a non-deterministic transition model. Since we have to be "real" in succeeding. Where does this leave us? Back to markov decision processes.

Now, lets learn PPP based on MDP and add another algo to our repertoire!

This is a lot common to RL - values, states, actions, transitions P(s, a, s'), policies ... and RL is basically powered by markov decision processes. 
As the PDF shows - State Utility Values calculated iteratively, and finally the Value Iteration algo.

---- 






